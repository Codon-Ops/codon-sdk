{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Codon Workload + OpenAI: Single and Multi-Agent Examples"
      ],
      "metadata": {
        "id": "WXYUXRWB7fQE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook demonstrates how to build agentic workloads with the Codon SDK, powered by the token-based runtime and OpenAI's `gpt-4.1-mini` model. It covers:\n",
        "\n",
        "1. A **single-agent** workflow that answers a user question.\n",
        "2. A **multi-agent** workflow where a planner, researcher, and writer collaborate.\n",
        "\n",
        "> **Note:** The cells are ready for Google Colab. Make sure you have access to the Codon SDK source and a valid OpenAI API key before running the examples."
      ],
      "metadata": {
        "id": "3YF78zdc80U4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Environment Preparation\n",
        "\n",
        "1. Install the necessary libraries (`openai` and `codon-sdk`) by running the cell below.\n",
        "1. Set your `OPENAI_API_KEY` as an environment variable\n"
      ],
      "metadata": {
        "id": "GKXVIJxB7jos"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AW_DYDv4CqzT"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip openai install git+https://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@github.com/Codon-Ops/codon-sdk.git#subdirectory=sdk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"ORG_NAMESPACE\"] = \"codon-example-org\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API Key:\")\n",
        "\n",
        "from datetime import datetime\n",
        "from typing import Any, Dict\n",
        "\n",
        "try:\n",
        "    from openai import OpenAI\n",
        "except ImportError as exc:\n",
        "    raise RuntimeError(\"Install the OpenAI Python package before running this notebook\") from exc\n",
        "\n",
        "from codon_sdk.agents import CodonWorkload\n",
        "\n",
        "client = OpenAI()\n",
        "MODEL_NAME = \"gpt-4.1-mini\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auz58ekyCzc8",
        "outputId": "384fc3f1-e894-4a99-bf16-e8c477f7d6e4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Helper Utilities\n",
        "\n",
        "We wrap OpenAI calls so prompts stay consistent and we can add cross-cutting logging."
      ],
      "metadata": {
        "id": "GX3kRxHY74Qa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def call_openai(prompt: str, *, system: str = \"You are a helpful assistant.\") -> str:\n",
        "    if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "        raise EnvironmentError(\"OPENAI_API_KEY must be set to use this notebook.\")\n",
        "    response = client.responses.create(\n",
        "        model=MODEL_NAME,\n",
        "        input=[\n",
        "            {\"role\": \"system\", \"content\": system},\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "        ],\n",
        "        max_output_tokens=600,\n",
        "    )\n",
        "    return response.output_text.strip()\n",
        "\n",
        "def print_ledger(report):\n",
        "  for event in report.ledger:\n",
        "    if event.event_type == \"node_completed\":\n",
        "      print(f\"{event.timestamp.isoformat()} | {event.event_type} | {event.source_node}\")\n",
        "    else:\n",
        "      print(f\"{event.timestamp.isoformat()} | {event.event_type} | {event.source_node} -> {event.target_node}\")"
      ],
      "metadata": {
        "id": "jXoAgT_IDBC5"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Single-Agent Workload\n",
        "\n",
        "The single-agent workflow receives a user question, crafts a prompt, calls OpenAI, and returns the answer. Audit events capture each step."
      ],
      "metadata": {
        "id": "Go9UYdJr78h5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a workload\n",
        "workload = CodonWorkload(name=\"QA-Agent\", version=\"0.1.0\")\n",
        "\n",
        "# Define node(s)\n",
        "def call_model(message: Dict[str, Any], *, runtime, context):\n",
        "  prompt = message[\"question\"]\n",
        "  answer = call_openai(prompt, system=\"You are a helpful assistant that answers questions you are asked.\")\n",
        "  runtime.record_event(\"call_model\", metadata={\"answer_length\": len(answer)})\n",
        "  runtime.emit(\"finalize\", {\"question\": message[\"question\"], \"answer\": answer})\n",
        "  return answer\n",
        "\n",
        "def prompt_builder(message: Dict[str, Any], *, runtime, context):\n",
        "  question = message[\"question\"]\n",
        "  prompt = (\n",
        "      \"Answer the user's question in clear, friendly prose.\"\n",
        "      f\"Question: {question}\"\n",
        "  )\n",
        "  runtime.record_event(\"prompt_created\", metadata={\"length\": len(prompt)})\n",
        "  runtime.emit(\"call_model\", {\"question\": question})\n",
        "  return prompt\n",
        "\n",
        "def finalize(message: Dict[str, Any], *, runtime, context):\n",
        "  result = {\n",
        "      \"question\": message[\"question\"],\n",
        "      \"answer\": message[\"answer\"],\n",
        "      \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n",
        "  }\n",
        "  runtime.record_event(\"finalized\", metadata={\"question_hash\": hash(message[\"question\"])})\n",
        "  return result\n",
        "\n",
        "# Add the node(s)\n",
        "workload.add_node(call_model, name=\"call_model\", role=\"llm\")\n",
        "workload.add_node(finalize, name=\"finalize\", role=\"postprocess\")\n",
        "workload.add_node(prompt_builder, name=\"prompt_builder\", role=\"format_prompt\")\n",
        "\n",
        "# Define the edge(s)\n",
        "workload.add_edge(\"prompt_builder\", \"call_model\")\n",
        "workload.add_edge(\"call_model\", \"finalize\")"
      ],
      "metadata": {
        "id": "Rm0YcYhCqUu-"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report = workload.execute({\"question\": \"What is the meaning of life, the universe, and everything?\"}, deployment_id=\"local\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pp5KWYPMsq5e",
        "outputId": "e2ff8b2c-7176-4b2a-8037-e6f50fe5f6c9"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2744524327.py:26: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the results from the final node\n",
        "\n",
        "report.node_results(\"finalize\")[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIQf-7bIw495",
        "outputId": "81cef806-18a0-452e-b749-69015969d325"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'What is the meaning of life, the universe, and everything?',\n",
              " 'answer': 'The phrase \"the meaning of life, the universe, and everything\" is famously answered as \"42\" in Douglas Adams\\' science fiction series *The Hitchhiker\\'s Guide to the Galaxy*. In a broader philosophical or spiritual sense, the meaning of life varies depending on individual beliefs, cultures, and perspectives. It can involve seeking purpose, happiness, knowledge, connection, or fulfillment.\\n\\nIf you\\'re interested, I can share different philosophical views or ideas from various traditions on the meaning of life!',\n",
              " 'timestamp': '2025-09-24T22:56:29.455993Z'}"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Idempotent logic_id is tied to the workload we defined\n",
        "\n",
        "workload.logic_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "HCkpo-GYyAGS",
        "outputId": "6790c602-14e6-4c68-8c09-347ea8a706cc"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'342790b3a3097293dd66de98da40d866284f609ac900ae6ad4a0ccdf8317be46'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Report context contains metadata about a specific workload run\n",
        "\n",
        "report.context"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1ZnAgOY5jsI",
        "outputId": "ff1d12f0-4192-480f-d1e8-8b06190307cc"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'deployment_id': 'local',\n",
              " 'workload_logic_id': '342790b3a3097293dd66de98da40d866284f609ac900ae6ad4a0ccdf8317be46',\n",
              " 'run_id': '781ce5c6-f2ff-4de2-a3f0-182d090054c2'}"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inspect the Audit Ledger\n",
        "\n",
        "Each event records how tokens traverse the graph."
      ],
      "metadata": {
        "id": "skk3ML2i8Ijj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_ledger(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AK5qHOuur99",
        "outputId": "4dc976ee-b962-4a20-d480-4b0c6b5a3d75"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-24T22:56:27.172281+00:00 | token_enqueued | __entry__ -> prompt_builder\n",
            "2025-09-24T22:56:27.172299+00:00 | token_dequeued | __entry__ -> prompt_builder\n",
            "2025-09-24T22:56:27.172316+00:00 | prompt_created | prompt_builder -> None\n",
            "2025-09-24T22:56:27.172350+00:00 | token_enqueued | prompt_builder -> call_model\n",
            "2025-09-24T22:56:27.172370+00:00 | node_completed | prompt_builder\n",
            "2025-09-24T22:56:27.172379+00:00 | token_dequeued | prompt_builder -> call_model\n",
            "2025-09-24T22:56:29.455758+00:00 | call_model | call_model -> None\n",
            "2025-09-24T22:56:29.455812+00:00 | token_enqueued | call_model -> finalize\n",
            "2025-09-24T22:56:29.455836+00:00 | node_completed | call_model\n",
            "2025-09-24T22:56:29.455846+00:00 | token_dequeued | call_model -> finalize\n",
            "2025-09-24T22:56:29.456014+00:00 | finalized | finalize -> None\n",
            "2025-09-24T22:56:29.456029+00:00 | node_completed | finalize\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Multi-Agent Workload\n",
        "\n",
        "We now orchestrate a planner, researcher, and writer. They collaborate by emitting tokens to one another while sharing per-run state."
      ],
      "metadata": {
        "id": "ifqlX3BE9UPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_multi_agent_workload() -> CodonWorkload:\n",
        "    workload = CodonWorkload(name=\"Research-Writer\", version=\"0.1.0\")\n",
        "\n",
        "    def planner(message: Dict[str, Any], *, runtime, context):\n",
        "        topic = message[\"topic\"]\n",
        "        prompt = (\n",
        "            \"Design a concise research plan outlining key angles and questions.\"\n",
        "            f\"Topic: {topic}\"\n",
        "            \"Return a numbered list with three focus areas.\"\n",
        "        )\n",
        "        plan = call_openai(prompt, system=\"You are a strategic project planner.\")\n",
        "        runtime.state[\"plan\"] = plan\n",
        "        runtime.emit(\"researcher\", {\"topic\": topic, \"plan\": plan})\n",
        "        return plan\n",
        "\n",
        "    def researcher(message: Dict[str, Any], *, runtime, context):\n",
        "        prompt = (\n",
        "            \"Given this plan, provide bullet insights (max 3 per focus area).\"\n",
        "            f\"Plan: {message['plan']}\"\n",
        "        )\n",
        "        insights = call_openai(prompt, system=\"You are an expert analyst.\")\n",
        "        runtime.state[\"insights\"] = insights\n",
        "        runtime.emit(\n",
        "            \"writer\",\n",
        "            {\n",
        "                \"topic\": message[\"topic\"],\n",
        "                \"plan\": message[\"plan\"],\n",
        "                \"insights\": insights,\n",
        "            },\n",
        "        )\n",
        "        return insights\n",
        "\n",
        "    def writer(message: Dict[str, Any], *, runtime, context):\n",
        "        prompt = (\n",
        "            \"Write a concise executive summary (<=120 words) in a warm, professional tone.\"\n",
        "            f\"Topic: {message['topic']}\"\n",
        "            f\"Plan: {message['plan']}\"\n",
        "            f\"Insights: {message['insights']}\"\n",
        "        )\n",
        "        summary = call_openai(prompt, system=\"You are a skilled report writer.\")\n",
        "        runtime.record_event(\"summary_created\", metadata={\"length\": len(summary)})\n",
        "        return {\n",
        "            \"topic\": message[\"topic\"],\n",
        "            \"plan\": message[\"plan\"],\n",
        "            \"insights\": message[\"insights\"],\n",
        "            \"summary\": summary,\n",
        "        }\n",
        "\n",
        "    workload.add_node(planner, name=\"planner\", role=\"planner\")\n",
        "    workload.add_node(researcher, name=\"researcher\", role=\"analyst\")\n",
        "    workload.add_node(writer, name=\"writer\", role=\"author\")\n",
        "    workload.add_edge(\"planner\", \"researcher\")\n",
        "    workload.add_edge(\"researcher\", \"writer\")\n",
        "\n",
        "    return workload"
      ],
      "metadata": {
        "id": "ZltcK9AAGKmZ"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multi_agent = build_multi_agent_workload()\n",
        "project = {\"topic\": \"The impact of community gardens on urban wellbeing\"}\n",
        "multi_report = multi_agent.execute(project, deployment_id=\"colab-demo\", max_steps=20)\n",
        "final_document = multi_report.node_results(\"writer\")[-1]\n",
        "final_document[\"summary\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "hhY5k90mGbVJ",
        "outputId": "c25fd473-f486-4e0d-c25f-7c27fd1563b9"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Community gardens play a vital role in enhancing urban wellbeing by promoting physical activity, reducing stress, and improving nutrition through fresh produce. They act as dynamic social hubs, fostering neighborhood connections, cultural exchange, and a strong sense of belonging across diverse groups. Environmentally, these gardens boost urban biodiversity and green space quality, while economically offering savings on food costs and potentially raising property values. Moreover, community gardens cultivate sustainability awareness through eco-friendly practices like composting and water conservation. Together, these benefits highlight community gardens as invaluable assets that nurture healthier, more connected, and environmentally conscious urban communities.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Plan:\", multi_report.node_results(\"planner\")[0])\n",
        "print(\"Insights:\", multi_report.node_results(\"researcher\")[0])\n",
        "print(\"Summary:\", final_document[\"summary\"])\n",
        "print(f\"Total ledger events: {len(multi_report.ledger)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayx8_xdyG1ZX",
        "outputId": "17c077c4-f706-44a2-f92b-9b48478b186a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plan: 1. **Physical and Mental Health Benefits**  \n",
            "   - How do community gardens influence physical activity levels among urban residents?  \n",
            "   - What impact do community gardens have on stress reduction and overall mental health?  \n",
            "   - Are there measurable improvements in nutrition and dietary habits linked to participation in community gardening?\n",
            "\n",
            "2. **Social Cohesion and Community Engagement**  \n",
            "   - In what ways do community gardens foster social interaction and strengthen neighborhood ties?  \n",
            "   - How do community gardens contribute to a sense of belonging and reduce social isolation?  \n",
            "   - What roles do different demographic groups play in garden participation, and how does this affect community dynamics?\n",
            "\n",
            "3. **Environmental and Economic Effects**  \n",
            "   - How do community gardens impact local urban biodiversity and green space quality?  \n",
            "   - What economic benefits arise from community gardens, such as reduced food costs or increased property values?  \n",
            "   - How do community gardens contribute to sustainability practices and environmental awareness in urban settings?\n",
            "Insights: **Physical and Mental Health Benefits**  \n",
            "- Community gardens significantly increase physical activity by encouraging regular gardening tasks, which improves overall fitness among urban residents.  \n",
            "- Participation in community gardening reduces stress levels and enhances mental well-being by providing therapeutic outdoor exposure and a calming environment.  \n",
            "- Engagement in community gardens is associated with improved nutrition, as gardeners tend to consume more fresh fruits and vegetables harvested from the garden.\n",
            "\n",
            "**Social Cohesion and Community Engagement**  \n",
            "- Community gardens serve as social hubs that promote interaction, collaboration, and mutual support, thereby strengthening neighborhood relationships.  \n",
            "- By creating shared responsibilities and communal spaces, gardens foster a strong sense of belonging and help alleviate feelings of social isolation.  \n",
            "- Diverse demographic involvement—including different ages, ethnicities, and socioeconomic groups—enhances cultural exchange and enriches community dynamics.\n",
            "\n",
            "**Environmental and Economic Effects**  \n",
            "- Community gardens improve urban biodiversity by creating habitats for pollinators and native plant species, enhancing overall green space quality.  \n",
            "- They offer economic benefits by reducing household food expenses through homegrown produce and can contribute to increased local property values.  \n",
            "- Gardens promote sustainability by encouraging composting, water conservation, and awareness about environmentally friendly practices among urban residents.\n",
            "Summary: Community gardens play a vital role in enhancing urban wellbeing by promoting physical activity, reducing stress, and improving nutrition through fresh produce. They act as dynamic social hubs, fostering neighborhood connections, cultural exchange, and a strong sense of belonging across diverse groups. Environmentally, these gardens boost urban biodiversity and green space quality, while economically offering savings on food costs and potentially raising property values. Moreover, community gardens cultivate sustainability awareness through eco-friendly practices like composting and water conservation. Together, these benefits highlight community gardens as invaluable assets that nurture healthier, more connected, and environmentally conscious urban communities.\n",
            "Total ledger events: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_ledger(multi_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdQ4E17EGphE",
        "outputId": "1240fbf4-c60e-4959-c99d-26746fe0a466"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-24T22:37:37.377248+00:00 | token_enqueued | __entry__ -> planner\n",
            "2025-09-24T22:37:37.377267+00:00 | token_dequeued | __entry__ -> planner\n",
            "2025-09-24T22:37:42.104834+00:00 | token_enqueued | planner -> researcher\n",
            "2025-09-24T22:37:42.104870+00:00 | node_completed | planner\n",
            "2025-09-24T22:37:42.104884+00:00 | token_dequeued | planner -> researcher\n",
            "2025-09-24T22:37:47.449442+00:00 | token_enqueued | researcher -> writer\n",
            "2025-09-24T22:37:47.449495+00:00 | node_completed | researcher\n",
            "2025-09-24T22:37:47.449549+00:00 | token_dequeued | researcher -> writer\n",
            "2025-09-24T22:37:49.719177+00:00 | summary_created | writer -> None\n",
            "2025-09-24T22:37:49.719202+00:00 | node_completed | writer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multi_report.context"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3xTZn6mLYPU",
        "outputId": "6577ff2e-7d6e-420f-840b-4b9eac154586"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'deployment_id': 'colab-demo',\n",
              " 'workload_logic_id': '23c2e0201532b1c901c180a651965a19534e3952ce3031765ef399db3591df5c',\n",
              " 'run_id': 'fbc4f70d-2dec-47f5-a7cd-6ef8d2c02e00'}"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "project_2 = {\"topic\": \"The future of AI\"}\n",
        "report_2 = multi_agent.execute(project_2, deployment_id=\"colab-demo\")"
      ],
      "metadata": {
        "id": "7Q6lUTHGGsZ3"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report_2.node_results(\"writer\")[-1][\"summary\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "YP1ucbn4HzL9",
        "outputId": "5fcb7ea2-1d29-4640-9773-9da440fa1ef2"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The future of AI promises transformative advancements through the fusion of AI, machine learning, and edge computing, enabling more autonomous, real-time AIR systems with enhanced accuracy and transparency. Healthcare, finance, and defense will lead adoption, leveraging AI to optimize operations and decision-making. However, challenges like high costs, integration complexity, and data privacy remain. Importantly, ethical concerns around bias, surveillance, and accountability call for robust regulatory frameworks focused on transparency and consent. As AIR technologies evolve, workforce dynamics will shift, highlighting the need for upskilling and addressing public trust. Together, these developments chart a path toward responsible, impactful AI innovation across industries and society.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for event in report_2.ledger:\n",
        "  if event.event_type == \"node_completed\":\n",
        "    print(f\"{event.timestamp.isoformat()} | {event.event_type} | {event.source_node}\")\n",
        "  else:\n",
        "    print(f\"{event.timestamp.isoformat()} | {event.event_type} | {event.source_node} -> {event.target_node}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drMcC2sLH3HP",
        "outputId": "96c60dd7-12c7-475d-d8ec-28a0ae7c73c4"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-24T22:38:03.116352+00:00 | token_enqueued | __entry__ -> planner\n",
            "2025-09-24T22:38:03.116372+00:00 | token_dequeued | __entry__ -> planner\n",
            "2025-09-24T22:38:07.269641+00:00 | token_enqueued | planner -> researcher\n",
            "2025-09-24T22:38:07.269675+00:00 | node_completed | planner\n",
            "2025-09-24T22:38:07.269689+00:00 | token_dequeued | planner -> researcher\n",
            "2025-09-24T22:38:17.872185+00:00 | token_enqueued | researcher -> writer\n",
            "2025-09-24T22:38:17.872239+00:00 | node_completed | researcher\n",
            "2025-09-24T22:38:17.872259+00:00 | token_dequeued | researcher -> writer\n",
            "2025-09-24T22:38:20.356850+00:00 | summary_created | writer -> None\n",
            "2025-09-24T22:38:20.356873+00:00 | node_completed | writer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "report_2.context"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWw0Lsj2Kl2b",
        "outputId": "3b93add4-add4-4b03-dd91-46864aef9eef"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'deployment_id': 'colab-demo',\n",
              " 'workload_logic_id': '23c2e0201532b1c901c180a651965a19534e3952ce3031765ef399db3591df5c',\n",
              " 'run_id': '58e240a0-6c33-43d9-b028-d3e2bfa6c0c5'}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3b. Multi-Agent with Reflection (Cyclic Graph)\n",
        "\n",
        "To illustrate self-healing behaviour, we extend the research team with a critic. The writer's drafts are reviewed; if the critic requests revisions, the runtime emits a token back to the writer, forming a **cycle**. The process repeats until the critic accepts or a maximum number of reviews is reached."
      ],
      "metadata": {
        "id": "eWpuGhAl9c0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_reflective_multi_agent_workload(max_reviews: int = 2) -> CodonWorkload:\n",
        "    workload = CodonWorkload(name=\"Research-Writer-Reflect\", version=\"0.1.0\")\n",
        "\n",
        "    def planner(message: Dict[str, Any], *, runtime, context):\n",
        "        topic = message[\"topic\"]\n",
        "        runtime.state.setdefault(\"iteration\", 0)\n",
        "        prompt = (\n",
        "            \"Design a concise research plan outlining key angles and questions.\"\n",
        "            f\"Topic: {topic}\"\n",
        "            \"Return a numbered list with three focus areas.\"\n",
        "        )\n",
        "        plan = call_openai(prompt, system=\"You are a strategic project planner.\")\n",
        "        runtime.state[\"plan\"] = plan\n",
        "        runtime.emit(\n",
        "            \"researcher\",\n",
        "            {\n",
        "                \"topic\": topic,\n",
        "                \"plan\": plan,\n",
        "                \"feedback\": \"Include community wellbeing impacts.\",\n",
        "            },\n",
        "        )\n",
        "        return plan\n",
        "\n",
        "    def researcher(message: Dict[str, Any], *, runtime, context):\n",
        "        prompt = (\n",
        "            \"Given this plan, provide crisp bullet insights (max 3 per focus area).\"\n",
        "            f\"Plan: {message['plan']}\"\n",
        "        )\n",
        "        insights = call_openai(prompt, system=\"You are an expert analyst.\")\n",
        "        runtime.state[\"insights\"] = insights\n",
        "        runtime.emit(\n",
        "            \"writer\",\n",
        "            {\n",
        "                \"topic\": message[\"topic\"],\n",
        "                \"plan\": message[\"plan\"],\n",
        "                \"insights\": insights,\n",
        "                \"feedback\": message.get(\"feedback\", \"Focus on clarity.\"),\n",
        "            },\n",
        "        )\n",
        "        return insights\n",
        "\n",
        "    def writer(message: Dict[str, Any], *, runtime, context):\n",
        "        iteration = runtime.state.get(\"iteration\", 0) + 1\n",
        "        runtime.state[\"iteration\"] = iteration\n",
        "        feedback = message.get(\"feedback\") or runtime.state.get(\"feedback\", \"Be concise and factual.\")\n",
        "        prompt = (\n",
        "            f\"You are drafting iteration {iteration} of an executive summary.\"\n",
        "            \"Incorporate the feedback and stay under 150 words.\"\n",
        "            f\"Topic: {message['topic']}\"\n",
        "            f\"Plan: {message['plan']}\"\n",
        "            f\"Insights: {message['insights']}\"\n",
        "            f\"Feedback: {feedback}\"\n",
        "        )\n",
        "        summary = call_openai(prompt, system=\"You are a collaborative report writer.\")\n",
        "        runtime.record_event(\"draft_created\", metadata={\"iteration\": iteration, \"length\": len(summary)})\n",
        "        runtime.emit(\n",
        "            \"critic\",\n",
        "            {\n",
        "                \"topic\": message[\"topic\"],\n",
        "                \"plan\": message[\"plan\"],\n",
        "                \"insights\": message[\"insights\"],\n",
        "                \"summary\": summary,\n",
        "                \"iteration\": iteration,\n",
        "            },\n",
        "        )\n",
        "        return summary\n",
        "\n",
        "    def critic(message: Dict[str, Any], *, runtime, context):\n",
        "        summary = message[\"summary\"]\n",
        "        evaluation_prompt = (\n",
        "            \"You are a critical editor.\"\n",
        "            \"If the summary clearly references community wellbeing and looks polished, respond with EXACTLY 'ACCEPT'.\"\n",
        "            \"Otherwise respond with 'REVISION: <short feedback>'.\"\n",
        "            f\"Summary: {summary}\"\n",
        "        )\n",
        "        verdict = call_openai(evaluation_prompt, system=\"You are a meticulous QA reviewer.\")\n",
        "        verdict_clean = verdict.strip()\n",
        "        runtime.state[\"feedback\"] = verdict_clean\n",
        "\n",
        "        if verdict_clean.upper().startswith(\"ACCEPT\"):\n",
        "            payload = {\n",
        "                \"topic\": message[\"topic\"],\n",
        "                \"plan\": message[\"plan\"],\n",
        "                \"insights\": message[\"insights\"],\n",
        "                \"summary\": summary,\n",
        "                \"verdict\": verdict_clean,\n",
        "                \"iteration\": message[\"iteration\"],\n",
        "            }\n",
        "            runtime.emit(\"finalize\", payload)\n",
        "            return {\"status\": \"accepted\", \"verdict\": verdict_clean}\n",
        "\n",
        "        runtime.record_event(\"revision_requested\", metadata={\"verdict\": verdict_clean})\n",
        "        if runtime.state.get(\"iteration\", 0) >= max_reviews:\n",
        "            payload = {\n",
        "                \"topic\": message[\"topic\"],\n",
        "                \"plan\": message[\"plan\"],\n",
        "                \"insights\": message[\"insights\"],\n",
        "                \"summary\": summary,\n",
        "                \"verdict\": verdict_clean + \" (max reviews reached)\",\n",
        "                \"iteration\": message[\"iteration\"],\n",
        "            }\n",
        "            runtime.emit(\"finalize\", payload)\n",
        "            return {\"status\": \"forced_accept\", \"verdict\": verdict_clean}\n",
        "\n",
        "        runtime.emit(\n",
        "            \"writer\",\n",
        "            {\n",
        "                \"topic\": message[\"topic\"],\n",
        "                \"plan\": message[\"plan\"],\n",
        "                \"insights\": message[\"insights\"],\n",
        "                \"feedback\": verdict_clean,\n",
        "            },\n",
        "        )\n",
        "        return {\"status\": \"revision\", \"verdict\": verdict_clean}\n",
        "\n",
        "    def finalize(message: Dict[str, Any], *, runtime, context):\n",
        "        runtime.record_event(\"workflow_completed\", metadata={\"verdict\": message[\"verdict\"]})\n",
        "        return {\n",
        "            \"topic\": message[\"topic\"],\n",
        "            \"summary\": message[\"summary\"],\n",
        "            \"verdict\": message.get(\"verdict\", \"ACCEPT\"),\n",
        "            \"iterations\": runtime.state.get(\"iteration\", 0),\n",
        "            \"plan\": message[\"plan\"],\n",
        "            \"insights\": message[\"insights\"],\n",
        "        }\n",
        "\n",
        "    workload.add_node(planner, name=\"planner\", role=\"planner\")\n",
        "    workload.add_node(researcher, name=\"researcher\", role=\"analyst\")\n",
        "    workload.add_node(writer, name=\"writer\", role=\"author\")\n",
        "    workload.add_node(critic, name=\"critic\", role=\"qa\")\n",
        "    workload.add_node(finalize, name=\"finalize\", role=\"publisher\")\n",
        "\n",
        "    workload.add_edge(\"planner\", \"researcher\")\n",
        "    workload.add_edge(\"researcher\", \"writer\")\n",
        "    workload.add_edge(\"writer\", \"critic\")\n",
        "    workload.add_edge(\"critic\", \"writer\")\n",
        "    workload.add_edge(\"critic\", \"finalize\")\n",
        "\n",
        "    return workload"
      ],
      "metadata": {
        "id": "HITDZspcLL4R"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reflective_workload = build_reflective_multi_agent_workload(max_reviews=3)\n",
        "project = {\"topic\": \"The future of AI\"}\n",
        "reflective_report = reflective_workload.execute(project, deployment_id=\"colab-demo\", max_steps=60)\n",
        "reflective_result = reflective_report.node_results(\"finalize\")[-1]\n",
        "reflective_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_069TCd973z",
        "outputId": "8839cebd-2ccc-414d-8c64-9d2665360f2b"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'topic': 'The future of AI',\n",
              " 'summary': 'The future of AI-powered augmented and immersive reality (AIR) will be shaped by rapid technological advancements, market dynamics, and important ethical considerations. Emerging technologies like AI, machine learning, and advanced sensors will drive more autonomous and context-aware AIR systems, enhanced by improved hardware and seamless integration with digital ecosystems. Industries such as healthcare, manufacturing, logistics, and retail stand to gain considerably, though adoption faces challenges like high costs, integration complexity, and privacy concerns. Consumer preferences for personalized experiences and evolving regulations will further influence market growth. Importantly, AIR’s societal impact extends beyond technology, potentially transforming social interactions and daily life. Addressing ethical issues like privacy, job displacement, and ensuring community wellbeing through proactive governance are crucial. Economically, AIR will foster new business models and necessitate workforce reskilling to navigate evolving roles, highlighting its broad relevance to future innovation and social progress.',\n",
              " 'verdict': 'ACCEPT',\n",
              " 'iterations': 1,\n",
              " 'plan': '1. **Technological Advancements and Innovation**  \\n   - What emerging technologies (e.g., AI, machine learning, sensors) will drive the evolution of AIR?  \\n   - How will improvements in hardware and software impact AIR capabilities and applications?  \\n   - What role will interoperability and integration with other systems play in AIR development?\\n\\n2. **Market Trends and Adoption**  \\n   - Which industries are poised to benefit most from AIR advancements?  \\n   - What are the barriers to widespread adoption of AIR technologies?  \\n   - How will consumer preferences and regulatory environments shape AIR market growth?\\n\\n3. **Ethical, Social, and Economic Implications**  \\n   - What are the potential ethical concerns related to AIR deployment (e.g., privacy, job displacement)?  \\n   - How might AIR influence societal norms and daily life in the future?  \\n   - What economic impacts, including new business models and workforce changes, are anticipated?',\n",
              " 'insights': '**Technological Advancements and Innovation**  \\n- AI, machine learning, and advanced sensors will be primary drivers, enabling more autonomous, accurate, and context-aware AIR systems.  \\n- Continuous hardware improvements (e.g., lightweight materials, enhanced processing power) combined with sophisticated software will expand AIR’s capabilities and application scope.  \\n- Seamless interoperability and integration with existing digital ecosystems (IoT, cloud platforms) are crucial for scalable, versatile AIR solutions.\\n\\n**Market Trends and Adoption**  \\n- Sectors such as healthcare, manufacturing, logistics, and retail are positioned to gain significant efficiencies and innovation from AIR technologies.  \\n- Adoption barriers include high initial costs, complexity of integration, privacy/security concerns, and lack of standardized frameworks.  \\n- Consumer demand for personalized, real-time experiences alongside evolving regulations (data protection, safety standards) will strongly influence AIR market trajectories.\\n\\n**Ethical, Social, and Economic Implications**  \\n- Privacy risks and potential job displacement due to automation raise critical ethical challenges requiring proactive governance and transparency.  \\n- AIR has the potential to reshape social interactions and daily routines by blending digital information seamlessly into the real world.  \\n- Economic impact includes the rise of new business models centered on AIR services and the need for workforce reskilling to adapt to changing roles.'}"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Verdict:\", reflective_result[\"verdict\"])\n",
        "print(\"Iterations:\", reflective_result[\"iterations\"])\n",
        "print(\"Summary:\", reflective_result[\"summary\"][:400], \"...\")\n",
        "print(f\"Total ledger events: {len(reflective_report.ledger)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwxV3oz298dT",
        "outputId": "83384960-689b-429d-9b7f-b43b94b60f36"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verdict: ACCEPT\n",
            "Iterations: 1\n",
            "Summary: The future of AI-powered augmented and immersive reality (AIR) will be shaped by rapid technological advancements, market dynamics, and important ethical considerations. Emerging technologies like AI, machine learning, and advanced sensors will drive more autonomous and context-aware AIR systems, enhanced by improved hardware and seamless integration with digital ecosystems. Industries such as hea ...\n",
            "Total ledger events: 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_ledger(reflective_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BN6pl6P3-PVl",
        "outputId": "7b24547d-cbdd-488b-aa9d-50817d17211c"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-24T23:04:18.624835+00:00 | token_enqueued | __entry__ -> planner\n",
            "2025-09-24T23:04:18.624851+00:00 | token_dequeued | __entry__ -> planner\n",
            "2025-09-24T23:04:21.883689+00:00 | token_enqueued | planner -> researcher\n",
            "2025-09-24T23:04:21.883721+00:00 | node_completed | planner\n",
            "2025-09-24T23:04:21.883734+00:00 | token_dequeued | planner -> researcher\n",
            "2025-09-24T23:04:26.384397+00:00 | token_enqueued | researcher -> writer\n",
            "2025-09-24T23:04:26.384447+00:00 | node_completed | researcher\n",
            "2025-09-24T23:04:26.384467+00:00 | token_dequeued | researcher -> writer\n",
            "2025-09-24T23:04:29.610759+00:00 | draft_created | writer -> None\n",
            "2025-09-24T23:04:29.610813+00:00 | token_enqueued | writer -> critic\n",
            "2025-09-24T23:04:29.610869+00:00 | node_completed | writer\n",
            "2025-09-24T23:04:29.610880+00:00 | token_dequeued | writer -> critic\n",
            "2025-09-24T23:04:30.122496+00:00 | token_enqueued | critic -> finalize\n",
            "2025-09-24T23:04:30.122568+00:00 | node_completed | critic\n",
            "2025-09-24T23:04:30.122576+00:00 | token_dequeued | critic -> finalize\n",
            "2025-09-24T23:04:30.122618+00:00 | workflow_completed | finalize -> None\n",
            "2025-09-24T23:04:30.122627+00:00 | node_completed | finalize\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Roadmap: Persistence & Resumability\n",
        "\n",
        "This notebook uses the in-memory runtime. Upcoming enhancements will add persistence adapters for tokens, runtime state, and audit logs so long-running conversations can resume seamlessly. Refer to `docs/vision/codon-workload-design-philosophy.md` for the broader roadmap."
      ],
      "metadata": {
        "id": "uaIo4l0F-bFK"
      }
    }
  ]
}